# -*- coding: utf-8 -*-
"""optuna_vwap_reversal_pro_optimizer.py
==========================================
- Optimise VWAP Reversal Pro pour diff√©rentes directions (SHORT/LONG)
- Bas√© sur la structure de l'optimiseur Williams %R
- Utilise les fonctions de Tools.func_features_preprocessing
- AJOUT: Gestion USE_TRAIN_IN_OPTIMIZATION pour contr√¥ler l'utilisation du dataset TRAIN
- ‚úÖ CORRECTION: Bug d'alignement des indices corrig√©
"""

from __future__ import annotations
from pathlib import Path
import sys, time, math, optuna, pandas as pd, numpy as np
import threading
import warnings
from datetime import datetime
import chardet
from Tools.func_features_preprocessing import vwap_reversal_pro_optimized

STOP_OPTIMIZATION = False  # touche ¬≤ => arr√™t propre
TEST_ON_DEMAND = False  # touche & => test imm√©diat
from pynput import keyboard


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Key flags ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _on_press(key):
    global STOP_OPTIMIZATION, TEST_ON_DEMAND
    if hasattr(key, "char"):
        if key.char == "¬≤":
            print("\nüõë  Arr√™t demand√© (¬≤)")
            STOP_OPTIMIZATION = True
        elif key.char == "&":
            print("\nüß™  Test demand√© (&) ‚Äì sera ex√©cut√© apr√®s ce trial")
            TEST_ON_DEMAND = True


keyboard.Listener(on_press=_on_press, daemon=True).start()

# D√©sactiver les avertissements
warnings.filterwarnings("ignore")

# Import des modules pour l'interface
try:
    from pynput import keyboard
except ImportError:
    print("Module pynput non disponible - raccourci clavier d√©sactiv√©")


    class KeyboardListener:
        def __init__(self, *args, **kwargs): pass

        def start(self): pass

        def join(self): pass


    keyboard = type('keyboard', (), {'Listener': KeyboardListener})

try:
    from colorama import init, Fore, Back, Style

    init(autoreset=True)
except ImportError:
    print("Module colorama non disponible - couleurs d√©sactiv√©es")


    class DummyColor:
        def __getattr__(self, name): return ""


    Fore = DummyColor()
    Back = DummyColor()
    Style = DummyColor()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CONFIGURATION ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

RANDOM_SEED = 42

# üîß CONFIGURATION STRAT√âGIE
DIRECTION = "short"  # "short" ou "long"

# ====== MODIFICATION PRINCIPALE: Contr√¥le d'utilisation du dataset TRAIN ======
USE_TRAIN_IN_OPTIMIZATION = True  # Mettre False pour d√©sactiver l'utilisation du dataset TRAIN dans l'optimisation
USE_TRAIN_IN_OPTIMIZATION = False  # Mettre True pour utiliser TRAIN dans l'optimisation

# Pour VWAP Reversal, l'objectif est toujours de maximiser le WR
OPTIMIZATION_GOAL = "maximize"
GOAL_DESCRIPTION = "MAXIMISER"
import os
from pathlib import Path

print(
    f"{Fore.CYAN}üéØ STRAT√âGIE: VWAP Reversal Pro - {DIRECTION.upper()} ‚Üí {GOAL_DESCRIPTION} le winrate{Style.RESET_ALL}")

# Affichage de l'√©tat du dataset TRAIN
if not USE_TRAIN_IN_OPTIMIZATION:
    print(
        f"{Fore.YELLOW}‚ö†Ô∏è  TRAIN DATASET D√âSACTIV√â pour l'optimisation - Test√© pour information seulement{Style.RESET_ALL}")
else:
    print(f"{Fore.GREEN}‚úî TRAIN DATASET ACTIV√â pour l'optimisation{Style.RESET_ALL}")

# Fichiers de donn√©es
DIR = R"C:\Users\aulac\OneDrive\Documents\Trading\VisualStudioProject" \
      R"\Sierra_chart\xTickReversal\simu\5_0_5TP_6SL\merge"
print("=" * 80)
print("üîç TEST D'EXISTENCE DU R√âPERTOIRE")
print("=" * 80)

# Test d'existence avec os.path
print(f"üìÅ R√©pertoire test√©: {DIR}")
print(f"‚úÖ os.path.exists(): {os.path.exists(DIR)}")
print(f"‚úÖ os.path.isdir(): {os.path.isdir(DIR)}")

# üîß CONFIGURATION FLEXIBLE : Le dataset TRAIN est toujours charg√© pour les stats finales
Direction = DIRECTION.capitalize()  # Pour compatibilit√© avec les noms de fichiers
# Chemins des fichiers (TRAIN est toujours d√©fini pour pouvoir afficher les stats finales)
CSV_TRAIN = DIR + Rf"\Step5_5_0_5TP_6SL_010124_200625_extractOnlyFullSession_Only{DIRECTION}_feat__split2_01052024_30092024.csv"
CSV_VAL = DIR + Rf"\Step5_5_0_5TP_6SL_010124_200625_extractOnlyFullSession_Only{DIRECTION}_feat__split3_30092024_28022025.csv"
CSV_VAL1 = DIR + Rf"\Step5_5_0_5TP_6SL_010124_200625_extractOnlyFullSession_Only{DIRECTION}_feat__split4_02032025_15052025.csv"
CSV_TEST = DIR + Rf"\Step5_5_0_5TP_6SL_010124_200625_extractOnlyFullSession_Only{DIRECTION}_feat__split5_15052025_20062025.csv"

# üîß PARAM√àTRES D'OPTIMISATION VWAP REVERSAL PRO
# Ranges bas√©s sur vos param√®tres existants avec une marge pour l'exploration
LOOKBACK_MIN, LOOKBACK_MAX = 12, 40
MOMENTUM_MIN, MOMENTUM_MAX = 3, 20
Z_WINDOW_MIN, Z_WINDOW_MAX = 20, 60
ATR_PERIOD_MIN, ATR_PERIOD_MAX = 8, 38
ATR_MULT_MIN, ATR_MULT_MAX = 1.2, 3.1
EMA_FILTER_MIN, EMA_FILTER_MAX = 25, 90
VOL_LOOKBACK_MIN, VOL_LOOKBACK_MAX = 3, 17
VOL_RATIO_MIN_MIN, VOL_RATIO_MIN_MAX = 0.1, 0.6

print(f"üìä Optimisation VWAP Reversal Pro - Direction: {DIRECTION}")

# üîß CRIT√àRES DE VALIDATION
WINRATE_MIN = 0.53  # WR minimum acceptable
PCT_TRADE_MIN = 0.01  # % de candles trad√©es minimum
MIN_TRADES = 10  # Nombre minimum de trades pour validation

# Param√®tres d'optimisation Optuna
N_TRIALS = 5000
PRINT_EVERY = 10
ALPHA = 0.70  # Poids du WR dans le score
LAMBDA_WR = 0.5  # P√©nalit√© pour l'√©cart de WR entre datasets
LAMBDA_PCT = 0.5  # P√©nalit√© pour l'√©cart de PCT entre datasets
FAILED_PENALTY = -1.0  # P√©nalit√© pour √©chec


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CHARGEMENT DES DONN√âES ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def detect_file_encoding(file_path: str, sample_size: int = 100_000) -> str:
    with open(file_path, 'rb') as f:
        raw = f.read(sample_size)
    return chardet.detect(raw)['encoding']


def load_csv_complete(path: str | Path) -> tuple[pd.DataFrame, pd.DataFrame, int]:
    """
    Charge les donn√©es compl√®tes ET filtr√©es s√©par√©ment
    Returns:
        df_complete: DataFrame avec TOUTES les bougies chronologiques (pour VWAP)
        df_filtered: DataFrame avec seulement class_binaire ‚àà {0, 1} (pour les m√©triques)
        nb_sessions: Nombre de sessions
    """
    path = Path(path)
    encoding = detect_file_encoding(str(path))
    if encoding.lower() == "ascii":
        encoding = "ISO-8859-1"

    print(f"{path.name} ‚ûú encodage d√©tect√©: {encoding}")

    # Chargement COMPLET sans filtrage
    df_complete = pd.read_csv(path, sep=";", encoding=encoding, parse_dates=["date"], low_memory=False)

    # V√©rifier que les colonnes VWAP n√©cessaires existent
    required_cols = ['sc_VWAP', 'sc_close', 'sc_high', 'sc_low', 'sc_volume']
    missing_cols = [col for col in required_cols if col not in df_complete.columns]
    if missing_cols:
        print(f"{Fore.RED}‚ùå Colonnes manquantes: {missing_cols}{Style.RESET_ALL}")
        raise ValueError(f"Colonnes manquantes dans le dataset: {missing_cols}")

    # Correction de sc_sessionStartEnd
    df_complete["sc_sessionStartEnd"] = pd.to_numeric(df_complete["sc_sessionStartEnd"], errors="coerce")
    df_complete = df_complete.dropna(subset=["sc_sessionStartEnd"])
    df_complete["sc_sessionStartEnd"] = df_complete["sc_sessionStartEnd"].astype(int)

    # Compter les sessions
    nb_start = (df_complete["sc_sessionStartEnd"] == 10).sum()
    nb_end = (df_complete["sc_sessionStartEnd"] == 20).sum()
    nb_sessions = min(nb_start, nb_end)

    if nb_start != nb_end:
        print(f"{Fore.YELLOW}‚ö†Ô∏è Incoh√©rence sessions: {nb_start} d√©buts vs {nb_end} fins{Style.RESET_ALL}")
    else:
        print(f"{Fore.GREEN}‚úî {nb_sessions} sessions compl√®tes d√©tect√©es{Style.RESET_ALL}")

    # Num√©rotation des sessions
    df_complete["session_id"] = (df_complete["sc_sessionStartEnd"] == 10).cumsum().astype("int32")

    # ‚úÖ CORRECTION DU BUG: Cr√©er le dataset FILTR√â SANS reset_index
    df_filtered = df_complete[df_complete["class_binaire"].isin([0, 1])].copy()
    # ‚ùå LIGNE SUPPRIM√âE: df_filtered.reset_index(drop=True, inplace=True)

    print(f"üìä Donn√©es compl√®tes: {len(df_complete):,} bougies")
    print(f"üìä Donn√©es filtr√©es: {len(df_filtered):,} bougies ({len(df_filtered) / len(df_complete):.1%})")

    return df_complete, df_filtered, nb_sessions


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CALCUL VWAP REVERSAL PRO ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
def calculate_vwap_reversal_signal(df_complete: pd.DataFrame, df_filtered: pd.DataFrame,
                                   params: dict, direction: str) -> pd.Series:
    """
    Calcule le signal VWAP Reversal Pro sur donn√©es COMPL√àTES
    ‚úÖ Version optimis√©e utilisant l'alignement par index (comme Williams %R)

    Args:
        df_complete: DataFrame avec toutes les bougies chronologiques
        df_filtered: DataFrame avec seulement class_binaire ‚àà {0, 1}
        params: Dictionnaire des param√®tres VWAP Reversal
        direction: "short" ou "long"

    Returns:
        signal: Serie avec signal (0/1) index√©e sur df_filtered
    """

    # 1) Calculer le signal sur donn√©es COMPL√àTES (chronologiques)
    signal_complete, status_df = vwap_reversal_pro_optimized(
        df_complete,
        lookback=params['lookback'],
        momentum=params['momentum'],
        z_window=params['z_window'],
        atr_period=params['atr_period'],
        atr_mult=params['atr_mult'],
        ema_filter=params['ema_filter'],
        vol_lookback=params['vol_lookback'],
        vol_ratio_min=params['vol_ratio_min'],
        direction=direction,
        atr_ma="sma"
    )

    # 2) ‚úÖ APPROCHE PAR INDICES (plus rapide et fiable)
    # Ajouter le signal calcul√© au DataFrame complet
    df_complete['vwap_signal'] = signal_complete

    # R√©cup√©rer les signaux correspondant aux indices du DataFrame filtr√©
    signal_filtered = df_complete.loc[df_filtered.index, 'vwap_signal'].to_numpy()

    # Gestion des NaN √©ventuels (au cas o√π certains indices n'existent pas)
    signal_filtered = np.where(np.isnan(signal_filtered), 0, signal_filtered)

    # Debug : v√©rifier l'alignement (seulement au premier appel)
    if not hasattr(calculate_vwap_reversal_signal, '_debug_printed'):
        print(f"üîß Alignement VWAP: {len(signal_filtered)} signaux r√©cup√©r√©s pour {len(df_filtered)} lignes filtr√©es")
        print(
            f"   Signaux actifs: {np.sum(signal_filtered == 1)} / {len(signal_filtered)} ({np.mean(signal_filtered):.2%})")
        calculate_vwap_reversal_signal._debug_printed = True

    return pd.Series(signal_filtered.astype(int), index=df_filtered.index)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê M√âTRIQUES ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _metrics(df: pd.DataFrame, mask: pd.Series, original_len: int = None) -> tuple[float, float, int, int, int]:
    """Calcule les m√©triques pour un masque donn√©"""
    sub = df.loc[mask]
    if sub.empty:
        return 0.0, 0.0, 0, 0, 0

    wins = int((sub["class_binaire"] == 1).sum())
    losses = int((sub["class_binaire"] == 0).sum())
    total = wins + losses

    if len(sub) != total:
        print(f"‚ö†Ô∏è Warning: {len(sub) - total} lignes avec class_binaire invalide ignor√©es")

    base_len = original_len if original_len is not None else len(df)
    pct_trade = total / base_len
    sessions_covered = sub["session_id"].nunique()

    return wins / total if total > 0 else 0.0, pct_trade, wins, losses, sessions_covered


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê FONCTION DE TEST D'ALIGNEMENT ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def test_alignment(df_complete, df_filtered):
    """Test pour v√©rifier l'alignement des indices apr√®s correction"""
    print(f"\nüîç TEST D'ALIGNEMENT DES INDICES:")

    # Test sur quelques lignes
    sample_indices = df_filtered.index[:5]
    print(f"  Indices df_filtered[:5]: {sample_indices.tolist()}")
    print(f"  class_binaire df_complete[sample_indices]: {df_complete.loc[sample_indices, 'class_binaire'].tolist()}")
    print(f"  class_binaire df_filtered[:5]: {df_filtered['class_binaire'].iloc[:5].tolist()}")

    # V√©rification
    if df_complete.loc[sample_indices, 'class_binaire'].equals(df_filtered['class_binaire'].iloc[:5]):
        print(f"  {Fore.GREEN}‚úÖ Alignement correct !{Style.RESET_ALL}")
    else:
        print(f"  {Fore.RED}‚ùå Probl√®me d'alignement d√©tect√© !{Style.RESET_ALL}")

    # V√©rification plus compl√®te
    all_match = df_complete.loc[df_filtered.index, 'class_binaire'].equals(df_filtered['class_binaire'])
    if all_match:
        print(f"  {Fore.GREEN}‚úÖ Alignement complet v√©rifi√© sur {len(df_filtered)} lignes !{Style.RESET_ALL}")
    else:
        print(f"  {Fore.RED}‚ùå Probl√®mes d'alignement sur le dataset complet !{Style.RESET_ALL}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê OPTIMISATION OPTUNA ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Variables globales pour stocker les datasets
TRAIN_COMPLETE, TRAIN_FILTERED = None, None
VAL_COMPLETE, VAL_FILTERED = None, None
VAL1_COMPLETE, VAL1_FILTERED = None, None
TEST_COMPLETE, TEST_FILTERED = None, None

best_trial = {
    "score": -math.inf,
    "number": None,
    "wr_t": 0.0, "pct_t": 0.0, "suc_t": 0, "fail_t": 0, "sess_t": 0,
    "wr_v": 0.0, "pct_v": 0.0, "suc_v": 0, "fail_v": 0, "sess_v": 0,
    "wr_v1": 0.0, "pct_v1": 0.0, "suc_v1": 0, "fail_v1": 0, "sess_v1": 0,
    "avg_gap_wr": 0.0, "avg_gap_pct": 0.0,
    "params": {}
}


def objective(trial: optuna.trial.Trial) -> float:
    global best_trial

    # Sugg√©rer les param√®tres
    params = {
        "lookback": trial.suggest_int("lookback", LOOKBACK_MIN, LOOKBACK_MAX),
        "momentum": trial.suggest_int("momentum", MOMENTUM_MIN, MOMENTUM_MAX),
        "z_window": trial.suggest_int("z_window", Z_WINDOW_MIN, Z_WINDOW_MAX),
        "atr_period": trial.suggest_int("atr_period", ATR_PERIOD_MIN, ATR_PERIOD_MAX),
        "atr_mult": trial.suggest_float("atr_mult", ATR_MULT_MIN, ATR_MULT_MAX, step=0.1),
        "ema_filter": trial.suggest_int("ema_filter", EMA_FILTER_MIN, EMA_FILTER_MAX),
        "vol_lookback": trial.suggest_int("vol_lookback", VOL_LOOKBACK_MIN, VOL_LOOKBACK_MAX),
        "vol_ratio_min": trial.suggest_float("vol_ratio_min", VOL_RATIO_MIN_MIN, VOL_RATIO_MIN_MAX, step=0.05)
    }

    # ====== MODIFICATION: TOUJOURS CALCULER LES M√âTRIQUES TRAIN ======
    signal_train = calculate_vwap_reversal_signal(TRAIN_COMPLETE, TRAIN_FILTERED, params, DIRECTION)
    mask_train = signal_train == 1
    train_len = len(TRAIN_FILTERED)
    wr_t, pct_t, suc_t, fail_t, sess_t = _metrics(TRAIN_FILTERED, mask_train, train_len)

    # VAL et VAL1 obligatoires
    signal_val = calculate_vwap_reversal_signal(VAL_COMPLETE, VAL_FILTERED, params, DIRECTION)
    signal_val1 = calculate_vwap_reversal_signal(VAL1_COMPLETE, VAL1_FILTERED, params, DIRECTION)

    mask_val = signal_val == 1
    mask_val1 = signal_val1 == 1

    val_len = len(VAL_FILTERED)
    val1_len = len(VAL1_FILTERED)

    wr_v, pct_v, suc_v, fail_v, sess_v = _metrics(VAL_FILTERED, mask_val, val_len)
    wr_v1, pct_v1, suc_v1, fail_v1, sess_v1 = _metrics(VAL1_FILTERED, mask_val1, val1_len)

    # ====== V√âRIFICATION DES SEUILS ADAPT√âE ======
    # Pour les seuils, on ne consid√®re que les datasets utilis√©s dans l'optimisation
    datasets_to_check = [(wr_v, pct_v, suc_v + fail_v), (wr_v1, pct_v1, suc_v1 + fail_v1)]
    if USE_TRAIN_IN_OPTIMIZATION:
        datasets_to_check.append((wr_t, pct_t, suc_t + fail_t))

    for wr, pct, total_trades in datasets_to_check:
        if wr < WINRATE_MIN or pct < PCT_TRADE_MIN or total_trades < MIN_TRADES:
            return FAILED_PENALTY

    # Affichage conditionnel compact
    if trial.number % 10 == 0 or (wr_v >= WINRATE_MIN and wr_v1 >= WINRATE_MIN):
        if USE_TRAIN_IN_OPTIMIZATION:
            print(f"Trial {trial.number:>5d} | "
                  f"LB={params['lookback']:>2d} Mom={params['momentum']:>2d} Z={params['z_window']:>2d} "
                  f"ATR={params['atr_period']:>2d}/{params['atr_mult']:.1f} "
                  f"EMA={params['ema_filter']:>2d} Vol={params['vol_lookback']:>2d}/{params['vol_ratio_min']:.2f} | "
                  f"TR[{Fore.GREEN}{wr_t:.2%}{Style.RESET_ALL}/{pct_t:.2%}] "
                  f"V1[{Fore.GREEN}{wr_v:.2%}{Style.RESET_ALL}/{pct_v:.2%}] "
                  f"V2[{Fore.GREEN}{wr_v1:.2%}{Style.RESET_ALL}/{pct_v1:.2%}]")
        else:
            print(f"Trial {trial.number:>5d} | "
                  f"LB={params['lookback']:>2d} Mom={params['momentum']:>2d} Z={params['z_window']:>2d} "
                  f"ATR={params['atr_period']:>2d}/{params['atr_mult']:.1f} "
                  f"EMA={params['ema_filter']:>2d} Vol={params['vol_lookback']:>2d}/{params['vol_ratio_min']:.2f} | "
                  f"TR[{Fore.YELLOW}{wr_t:.2%}{Style.RESET_ALL}/{pct_t:.2%}](info) "
                  f"V1[{Fore.GREEN}{wr_v:.2%}{Style.RESET_ALL}/{pct_v:.2%}] "
                  f"V2[{Fore.GREEN}{wr_v1:.2%}{Style.RESET_ALL}/{pct_v1:.2%}]")

    # ====== CALCUL DES √âCARTS ADAPT√â ======
    if USE_TRAIN_IN_OPTIMIZATION:
        # Avec TRAIN : √©carts entre les 3 datasets
        gap_wr_tv = abs(wr_t - wr_v)
        gap_pct_tv = abs(pct_t - pct_v)
        gap_wr_tv1 = abs(wr_t - wr_v1)
        gap_pct_tv1 = abs(pct_t - pct_v1)
        gap_wr_vv1 = abs(wr_v - wr_v1)
        gap_pct_vv1 = abs(pct_v - pct_v1)

        avg_gap_wr = (gap_wr_tv + gap_wr_tv1 + gap_wr_vv1) / 3
        avg_gap_pct = (gap_pct_tv + gap_pct_tv1 + gap_pct_vv1) / 3

        # Score avec TRAIN
        score = (ALPHA * (wr_t + wr_v + wr_v1) / 3 +
                 (1 - ALPHA) * (pct_t + pct_v + pct_v1) / 3 -
                 LAMBDA_WR * avg_gap_wr -
                 LAMBDA_PCT * avg_gap_pct)
    else:
        # Sans TRAIN : √©cart seulement entre VAL et VAL1
        gap_wr_vv1 = abs(wr_v - wr_v1)
        gap_pct_vv1 = abs(pct_v - pct_v1)

        avg_gap_wr = gap_wr_vv1
        avg_gap_pct = gap_pct_vv1

        # Score sans TRAIN
        score = (ALPHA * (wr_v + wr_v1) / 2 +
                 (1 - ALPHA) * (pct_v + pct_v1) / 2 -
                 LAMBDA_WR * avg_gap_wr -
                 LAMBDA_PCT * avg_gap_pct)

    # Mise √† jour du meilleur essai
    if score > best_trial["score"]:
        print(f"{Fore.GREEN}‚úÖ NOUVEAU MEILLEUR ESSAI ! Score: {score:.4f}{Style.RESET_ALL}")
        best_trial = {
            "number": trial.number,
            "score": score,
            # M√©triques TRAIN (toujours stock√©es maintenant)
            "wr_t": wr_t, "pct_t": pct_t, "suc_t": suc_t, "fail_t": fail_t, "sess_t": sess_t,
            "wr_v": wr_v, "pct_v": pct_v, "suc_v": suc_v, "fail_v": fail_v, "sess_v": sess_v,
            "wr_v1": wr_v1, "pct_v1": pct_v1, "suc_v1": suc_v1, "fail_v1": fail_v1, "sess_v1": sess_v1,
            "avg_gap_wr": avg_gap_wr,
            "avg_gap_pct": avg_gap_pct,
            "params": params
        }

    return score


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê TEST SUR HOLD-OUT ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def calculate_test_metrics(params: dict):
    """Calcule les m√©triques sur le dataset TEST"""
    print(f"\n{Fore.CYAN}üßÆ Calcul sur DATASET TEST{Style.RESET_ALL}\n")

    # ====== RAPPEL DES STATISTIQUES FINALES SUR TOUS LES DATASETS ======
    def calculate_dataset_stats(df_complete, df_filtered, df_name, original_len):
        """Calcule et affiche les stats finales d'un dataset"""
        if df_complete is None or df_filtered is None:
            return

        # Calcul du signal
        signal = calculate_vwap_reversal_signal(df_complete, df_filtered, params, DIRECTION)
        mask = signal == 1

        wr, pct, suc, fail, sess = _metrics(df_filtered, mask, original_len)

        # ====== MODIFICATION: Indiquer si TRAIN est utilis√© pour l'optimisation ======
        if df_name == "TRAIN" and not USE_TRAIN_IN_OPTIMIZATION:
            info_suffix = f" {Fore.YELLOW}(info seulement){Style.RESET_ALL}"
        else:
            info_suffix = ""

        print(f"    {df_name}{info_suffix}: WR={Fore.GREEN}{wr:.2%}{Style.RESET_ALL}  pct={pct:.2%}  "
              f"‚úì{Fore.GREEN}{suc}{Style.RESET_ALL} ‚úó{Fore.RED}{fail}{Style.RESET_ALL}  "
              f"Total={Fore.CYAN}{suc + fail}{Style.RESET_ALL} (sessions: {sess})")

    print(f"{Fore.YELLOW}üìä RAPPEL - Statistiques finales avec param√®tres optimaux:{Style.RESET_ALL}")

    if TRAIN_COMPLETE is not None:
        calculate_dataset_stats(TRAIN_COMPLETE, TRAIN_FILTERED, "TRAIN", len(TRAIN_FILTERED))
    calculate_dataset_stats(VAL_COMPLETE, VAL_FILTERED, "VAL  ", len(VAL_FILTERED))
    calculate_dataset_stats(VAL1_COMPLETE, VAL1_FILTERED, "VAL1 ", len(VAL1_FILTERED))

    print(f"\n{Fore.YELLOW}üéØ R√âSULTATS SUR DATASET TEST:{Style.RESET_ALL}")

    # Calcul du signal
    signal_test = calculate_vwap_reversal_signal(TEST_COMPLETE, TEST_FILTERED, params, DIRECTION)
    mask_test = signal_test == 1

    test_len = len(TEST_FILTERED)
    wr_test, pct_test, suc_test, fail_test, sess_test = _metrics(TEST_FILTERED, mask_test, test_len)

    # Affichage d√©taill√© des param√®tres
    print(f"VWAP Reversal Pro {DIRECTION.upper()}")
    print(f"Param√®tres:")
    print(f"  ‚Ä¢ Lookback: {params['lookback']}")
    print(f"  ‚Ä¢ Momentum: {params['momentum']}")
    print(f"  ‚Ä¢ Z-Window: {params['z_window']}")
    print(f"  ‚Ä¢ ATR: Period={params['atr_period']}, Mult={params['atr_mult']:.2f}")
    print(f"  ‚Ä¢ EMA Filter: {params['ema_filter']}")
    print(f"  ‚Ä¢ Volume: Lookback={params['vol_lookback']}, Ratio={params['vol_ratio_min']:.2f}")

    print(f"\nR√©sultats:")
    print(f"WR={Fore.GREEN}{wr_test:.2%}{Style.RESET_ALL} | "
          f"PCT={pct_test:.2%} | "
          f"Trades={suc_test + fail_test} (‚úì{suc_test} ‚úó{fail_test}) | "
          f"Sessions={sess_test}")

    # Validation
    is_valid = (wr_test >= WINRATE_MIN and pct_test >= PCT_TRADE_MIN and
                (suc_test + fail_test) >= MIN_TRADES)

    print(f"\nCrit√®res: WR ‚â• {WINRATE_MIN:.1%}, PCT ‚â• {PCT_TRADE_MIN:.1%}, Trades ‚â• {MIN_TRADES}")

    if is_valid:
        print(f"{Fore.GREEN}‚úÖ VALIDE{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}‚ùå REJET{Style.RESET_ALL}")

    return wr_test, pct_test, suc_test, fail_test, sess_test, is_valid


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê PROGRAMME PRINCIPAL ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    global TRAIN_COMPLETE, TRAIN_FILTERED, VAL_COMPLETE, VAL_FILTERED
    global VAL1_COMPLETE, VAL1_FILTERED, TEST_COMPLETE, TEST_FILTERED
    global TEST_ON_DEMAND, STOP_OPTIMIZATION

    print(f"{Fore.CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê{Style.RESET_ALL}")
    print(f"{Fore.CYAN}   OPTIMISATION VWAP REVERSAL PRO - {DIRECTION.upper()}{Style.RESET_ALL}")
    print(f"{Fore.CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê{Style.RESET_ALL}\n")

    print(f"{Fore.CYAN}Chargement des donn√©es...{Style.RESET_ALL}")

    # ====== MODIFICATION: TRAIN toujours charg√© mais usage conditionnel ======
    TRAIN_COMPLETE, TRAIN_FILTERED, train_sessions = load_csv_complete(CSV_TRAIN)
    VAL_COMPLETE, VAL_FILTERED, val_sessions = load_csv_complete(CSV_VAL)
    VAL1_COMPLETE, VAL1_FILTERED, val1_sessions = load_csv_complete(CSV_VAL1)
    TEST_COMPLETE, TEST_FILTERED, test_sessions = load_csv_complete(CSV_TEST)

    # ‚úÖ TEST D'ALIGNEMENT APR√àS CHARGEMENT
    test_alignment(TRAIN_COMPLETE, TRAIN_FILTERED)

    print(f"\nüìä R√âSUM√â DES DATASETS :")
    print("‚îÄ" * 60)

    datasets_info = []
    if TRAIN_COMPLETE is not None:
        usage_info = " (utilis√© pour optimisation)" if USE_TRAIN_IN_OPTIMIZATION else " (info seulement)"
        datasets_info.append(("TRAIN", TRAIN_FILTERED, train_sessions, usage_info))

    datasets_info.extend([
        ("VAL", VAL_FILTERED, val_sessions, ""),
        ("VAL1", VAL1_FILTERED, val1_sessions, ""),
        ("TEST", TEST_FILTERED, test_sessions, "")
    ])

    for label, df_filtered, sessions, usage in datasets_info:
        if df_filtered is not None:
            print(f"{label:5} | lignes filtr√©es={len(df_filtered):,} | "
                  f"WR brut={(df_filtered['class_binaire'] == 1).mean():.2%} | Sessions={sessions}{usage}")

    print("‚îÄ" * 60)

    # Configuration de l'√©tude Optuna
    study = optuna.create_study(
        direction="maximize",
        sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)
    )

    print(f"\n{Fore.CYAN}D√©but de l'optimisation ({N_TRIALS} essais)...{Style.RESET_ALL}\n")

    # Boucle d'optimisation
    start_time = time.time()

    for done in range(1, N_TRIALS + 1):

        # 1) sortie propre demand√©e ?
        if STOP_OPTIMIZATION:
            break

        # 2) un seul trial
        study.optimize(objective, n_trials=1)

        # 3) test imm√©diat (&) avec les meilleurs params courants
        if TEST_ON_DEMAND and best_trial["number"] is not None:
            TEST_ON_DEMAND = False
            print("\nüß™ TEST √† la vol√©e ‚Äì meilleurs param√®tres connus")
            calculate_test_metrics(best_trial["params"])

        # 4) r√©cap + test p√©riodique toutes PRINT_EVERY it√©rations
        if done % PRINT_EVERY == 0:
            elapsed = time.time() - start_time
            print(
                f"\n{Fore.CYAN}"
                f"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê R√âSUM√â APR√àS {done} ESSAIS "
                f"(VWAP REVERSAL PRO - {DIRECTION.upper()}) "
                f"[{elapsed / 60:.1f} min] "
                f"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
                f"{Style.RESET_ALL}"
            )
            if best_trial["number"] is not None:
                params = best_trial["params"]
                print(f"Meilleur: Trial #{best_trial['number']} | Score={best_trial['score']:.4f}")
                print("Param√®tres optimaux:")
                print(f"  ‚Ä¢ Lookback={params['lookback']}, Momentum={params['momentum']}, "
                      f"Z-Window={params['z_window']}")
                print(f"  ‚Ä¢ ATR: Period={params['atr_period']}, Mult={params['atr_mult']:.2f}")
                print(f"  ‚Ä¢ EMA={params['ema_filter']}, Vol: LB={params['vol_lookback']}, "
                      f"Ratio={params['vol_ratio_min']:.2f}")

                # ====== MODIFICATION: AFFICHAGE ADAPT√â SELON L'UTILISATION DE TRAIN ======
                if USE_TRAIN_IN_OPTIMIZATION:
                    metrics_parts = [
                        f"TR[{Fore.GREEN}{best_trial['wr_t']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_t']:.2%}]",
                        f"V1[{Fore.GREEN}{best_trial['wr_v']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_v']:.2%}]",
                        f"V2[{Fore.GREEN}{best_trial['wr_v1']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_v1']:.2%}]"
                    ]
                else:
                    metrics_parts = [
                        f"TR[{Fore.YELLOW}{best_trial['wr_t']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_t']:.2%}](info)",
                        f"V1[{Fore.GREEN}{best_trial['wr_v']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_v']:.2%}]",
                        f"V2[{Fore.GREEN}{best_trial['wr_v1']:.2%}{Style.RESET_ALL}/"
                        f"{best_trial['pct_v1']:.2%}]"
                    ]

                print("M√©triques: " + " ".join(metrics_parts))

                # üßÆ test syst√©matique sur CSV_TEST
                calculate_test_metrics(best_trial["params"])

    # R√âSUM√â FINAL
    print(f"\n{Fore.YELLOW}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê R√âSUM√â FINAL ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê{Style.RESET_ALL}")
    if best_trial["number"] is not None:
        params = best_trial["params"]
        print(f"\nüèÜ MEILLEUR ESSAI #{best_trial['number']} (Score: {best_trial['score']:.4f})")
        print(f"üéØ Strat√©gie: VWAP Reversal Pro - {DIRECTION.upper()}")

        # ====== MODIFICATION: Indication du mode d'utilisation de TRAIN ======
        if USE_TRAIN_IN_OPTIMIZATION:
            print(f"üîß Mode: TRAIN utilis√© pour l'optimisation")
        else:
            print(f"üîß Mode: TRAIN test√© pour information seulement")

        print(f"\nüìã PARAM√àTRES OPTIMAUX:")
        print(f"params_{DIRECTION} = {{")
        print(f"    'lookback': {params['lookback']},")
        print(f"    'momentum': {params['momentum']},")
        print(f"    'z_window': {params['z_window']},")
        print(f"    'atr_period': {params['atr_period']},")
        print(f"    'atr_mult': {params['atr_mult']:.10f},")
        print(f"    'ema_filter': {params['ema_filter']},")
        print(f"    'vol_lookback': {params['vol_lookback']},")
        print(f"    'vol_ratio_min': {params['vol_ratio_min']:.10f},")
        print(f"}}")

        print(f"\nüìä M√âTRIQUES FINALES:")

        # ====== MODIFICATION: AFFICHAGE ADAPT√â SELON L'UTILISATION DE TRAIN ======
        if USE_TRAIN_IN_OPTIMIZATION:
            metrics_to_show = [("TRAIN", "t"), ("VAL", "v"), ("VAL1", "v1")]
        else:
            metrics_to_show = [("TRAIN (info)", "t"), ("VAL", "v"), ("VAL1", "v1")]

        for label, prefix in metrics_to_show:
            wr = best_trial[f"wr_{prefix}"]
            pct = best_trial[f"pct_{prefix}"]
            suc = best_trial[f"suc_{prefix}"]
            fail = best_trial[f"fail_{prefix}"]
            total = suc + fail
            print(f"  ‚Ä¢ {label:12}: WR={wr:.2%} | Trades={total} (‚úì{suc}, ‚úó{fail}) | PCT={pct:.2%}")

        print(f"\nüß™ TEST FINAL:")
        calculate_test_metrics(best_trial["params"])

    elapsed_total = time.time() - start_time
    print(f"\n‚úÖ Fin de l'optimisation. Dur√©e totale: {elapsed_total / 60:.1f} minutes")
    print(f"   Moyenne par essai: {elapsed_total / done:.2f} secondes")


if __name__ == "__main__":
    main()